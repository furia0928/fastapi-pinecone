import os
import time
from uuid import uuid4
from langchain_openai import OpenAIEmbeddings
from pinecone import Pinecone, ServerlessSpec
from dotenv import load_dotenv

load_dotenv()
# ğŸ“Œ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "your-openai-api-key")
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY", "your-pinecone-api-key")

# ğŸ“Œ Pinecone í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
pc = Pinecone(api_key=PINECONE_API_KEY)

# ğŸ“Œ ì¸ë±ìŠ¤ ì„¤ì •
INDEX_NAME = "markdown-index"
NAMESPACE = "langchain"

# ğŸ“Œ Pinecone ì„œë²„ë¦¬ìŠ¤ ì¸ë±ìŠ¤ ìƒì„±
if INDEX_NAME not in [i.name for i in pc.list_indexes()]:
    pc.create_index(
        name=INDEX_NAME,
        dimension=1536,  # OpenAI ì„ë² ë”© ë²¡í„° í¬ê¸°
        metric="cosine",
        spec=ServerlessSpec(cloud="aws", region="us-east-1")
    )

# ğŸ“Œ Pinecone ì¸ë±ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸°
index = pc.Index(INDEX_NAME)

# ğŸ“Œ Markdown íŒŒì¼ì´ ìˆëŠ” í´ë” ê²½ë¡œ
FOLDER_PATH = "./markdown_outputs"
BATCH_SIZE = 50  # í•œ ë²ˆì— ì—…ì„œíŠ¸í•  ë²¡í„° ê°œìˆ˜


# ğŸ“Œ OpenAI ì„ë² ë”© ìƒì„± í•¨ìˆ˜
def get_embedding(text):
    """í…ìŠ¤íŠ¸ë¥¼ OpenAI ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
    embedding_model = OpenAIEmbeddings(
        model="text-embedding-ada-002",
        api_key=OPENAI_API_KEY
    )
    return embedding_model.embed_query(text)


# ğŸ“Œ í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ„ëŠ” í•¨ìˆ˜
def chunk_text(text, chunk_size=512, overlap=50):
    """í…ìŠ¤íŠ¸ë¥¼ ì¼ì • í¬ê¸°ë¡œ ë‚˜ëˆ„ê³ , ê²¹ì¹˜ëŠ” ë¶€ë¶„ ìœ ì§€"""
    chunks = []
    for i in range(0, len(text), chunk_size - overlap):
        chunks.append(text[i : i + chunk_size])
    return chunks


# ğŸ“Œ Markdown íŒŒì¼ì„ Pineconeì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜
def process_markdown_files(folder_path):
    all_vectors = []

    for filename in os.listdir(folder_path):
        if filename.endswith(".md"):
            file_path = os.path.join(folder_path, filename)

            with open(file_path, "r", encoding="utf-8") as f:
                text = f.read()

            # ğŸ“Œ í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• 
            chunks = chunk_text(text)

            for i, chunk in enumerate(chunks):
                embedding = get_embedding(chunk)

                vector_id = f"{filename}_{i}"
                metadata = {"filename": filename, "chunk_id": i, "text": chunk}

                all_vectors.append((vector_id, embedding, metadata))

                # ğŸ“Œ BATCH ì—…ì„œíŠ¸
                if len(all_vectors) >= BATCH_SIZE:
                    index.upsert(vectors=all_vectors, namespace=NAMESPACE)
                    print(f"âœ… {len(all_vectors)}ê°œ ë²¡í„° ì €ì¥ ì™„ë£Œ!")
                    all_vectors = []  # ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”

    # ğŸ“Œ ë§ˆì§€ë§‰ ë‚¨ì€ ë°ì´í„° ì—…ì„œíŠ¸
    if all_vectors:
        index.upsert(vectors=all_vectors, namespace=NAMESPACE)
        print(f"âœ… ìµœì¢… {len(all_vectors)}ê°œ ë²¡í„° ì €ì¥ ì™„ë£Œ!")


# ğŸ“Œ ì‹¤í–‰
process_markdown_files(FOLDER_PATH)

# ğŸ“Œ ë²¡í„° ì €ì¥ í™•ì¸
time.sleep(5)  # Pinecone ë°˜ì˜ ëŒ€ê¸°
stats = index.describe_index_stats()
print("ğŸ“Œ Pinecone ì¸ë±ìŠ¤ ìƒíƒœ:", stats)
print("ğŸ¯ ëª¨ë“  Markdown íŒŒì¼ì´ Pineconeì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
